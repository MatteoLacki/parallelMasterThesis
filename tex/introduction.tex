\addcontentsline{toc}{chapter}{Introduction}\label{Introduction}

The \PTalgo\, is an extension to standard \MHalgo\,whose aim is to draw samples from a given target distribution. The \PTalgo\,is also known as the Replica Monte Carlo Simulation. The principle aim of the algorithm is to approximate the integrals 

\begin{equation*}
	\expect g(X) = \int_\Omega g(x) \dip(x),
\end{equation*}

where $X\sim \pi$, $\pi$ is a measure, and $g$ is some $\mathbb{L}^1(\Pi)$ function. In practical applications $\pi$ has either a density function, or a probability function. The \MHalgo\, proceeds by creating a sequence of sample points, \sample,\,from the limiting distribution of a certain operator, $\mathcal{Q}$, chosen so that its invariant distribution exists, is unique, and coincides with $\pi$. The approximation is then taken to be simply

\begin{equation*}
	\expect g(X) \approx \frac{1}{\nn}\sum_{i = 1}^\nn g(X^{[i]}).
\end{equation*}

The problem with the usual \MHalgo\, is that it has poor mixing abilities, so that the above approximations may be biased when $\pi$ is multimodial. The \PT\, provides a potential solution to this problem by enlarging the state space. Several copies of progressively modified operators are run on this space, the differences between them depending on one parameter only\footnote{There are many similarities with the homotopy theory in this regard.}. This parameter is traditionally called {\it the temperature}, because of the physical interpretion it had in the seminal work of \citet{RobertSwendsen}. 

The sample points created by individual operators are sometimes refered to as chains. The idea of simultaneous simulations is the first of two consituents of the \PT, the other being that of interlacing results from different chains. The new distributions have their probability mass spread in regions around the clusters of probability of the target-measure in a less and less concentrated way. Consequently, simulations from these distributions explore more of the state-space at the cost of higher variance. The subsequent random interchange between samples generated from different chains enables the base-level chain, corresponding to the target distribution, to explore most of its structure resulting in simulations better estimates.

The applicability of the \PT\, stems from the more and more widespread use of the Bayesian modeling. In fact, it is the need of calculating some the a posteriori distributions that in many cases has driven scientists to develop efficient sampling techniques in the first place. Nowadays the use of Bayesian models spreads from meteorology, to chemistry, from OCRs, to biogenetics. And in all of these fields it is very natural for the multimodial distributions at some point to appear.