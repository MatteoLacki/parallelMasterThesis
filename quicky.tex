%!TEX program = <xelatex>
\documentclass{book}
\usepackage{mystyle}
\begin{document}

%!TEX root = <parallelTemperingMaster.tex>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{ Implementation }\label{Implementation}

In this chapter we will present the implementation of the \PT, as described in \todo{Add Chapter on Theory}

The analysis of the algorithm in all its complexity called for the development
of a more structurised template for carrying out numerical computations. The
\PT, being an extension to the \MH, does naturally share many similarities its structure. Both algorithms can have very
abstract formulations and can be carried out theoretically on any countably-
generated measurable space. Practical considerations would never go that far.
However, one cannot, in principle, discard the use of Stochastic Simulations in solving many real-life modelling problems such as, for instance, the Bayesian model selection, or Ising-type modelling of crystallic structures. The mulitude of potential applications calls for a reasonably flexible implemention of the \PT. To overcome these problems, the object-oriented paradigm was used in this work, so that the \sspace\, and the \algo\, were two separate entities. 

Having realised the need for modularity, it seemed natural to take the whole idea one step further and develop a general template for Metropolis-Hastings-like simulations, going way beyond the idea of a task-specific computer programme. For there are other potential developments of the \MH\, that are being used, all baring strong similarities in stuctures of these algorithms. Our template's goal was therefore to provide basic building blocks used for simulations, leaving the practitioners concentrate on the analysis. The template is codenamed \ssimul \, and that will be the \RR\, package name when shipped.

\section{Division into objects}

To assure real modularity of our template, more divisions were proposed than only the one mentioned at the beginning of this chapter. The overall structure is represented in Figure \ref{objectStructure}.

We already mentioned the separation of the \algo\, from the \sspace. It is useful to think of the \algo\, as of a decision-maker. Its role is restricted to making decisions on acceptance or rejections of the proposals generated by the \sspace\, and then on giving orders to the \sspace\, to perform subsequent actions. The information on which the Algorithm bases its decisions depends on the points from the State Space only indirectly, via the evaluations of densities\footnote{In the discrete case -- probability functions} at the proposal points \todo{Mathy this by adding equations}.

 A third candidate for an entity thus appears - namely an object whose methods would serve to measure some characteristic of the State Space sample points for the use in the decision-making of the Algorithm. We called this entity the Target Measure. 

The very idea behind the Target Measure entity is that it should serve as a container for user-defined probability function or a density together with every additional data-structure required for its evaluation. Moreover, in case the user was interested in testing the \PT's potential on some toy-example, that was analytically tractable or could be simulated using any other simpler and more efficient technique, the Target Measure entity would be the place to store any additional methods tied with this particular distribution. For example, in our simulations (confront Chapter \todo{simulationsAndResults}) we could  additionally provide efficient methods for quantile simulations and evaluates of the real distribuant. Implementations of these functions were collected as methods of the appropriately named instatiation of the Target Measure structure.  



\begin{figure}
	\begin{tikzpicture}
		[-,thick,%
		  every node/.style={shape=rectangle,inner sep=3pt,draw,thick}]
		\footnotesize
		\node {Simulations}
		  [sibling distance=4cm]
		  child {node {Algorithms}
		  	child {node {Metropolis-Hastings}
		  		child {node {ParallelTempering}	
		  		}
		  	}	
		  }
		  child {node {StateSpaces}
		    child {node {Real}
		    	child {node {RealTempered}
		    	}
		    }
		  }
		  child {node {TargetMeasures}
		    [sibling distance=2cm]
		    child {node {Liang}
		    	child {node {Matteo}}
		    }
		    child {node {Unnormalised}}
		  };
	\end{tikzpicture}
	\caption{Current operational entity-relations diagram.}\label{objectStructure}
\end{figure}

The reason for separating the Target Measure from the State Space is again dictated by the modularity requirement. Totally different models can be modelled on the same State Space, the only difference being the way the probability is assigned. It is therefore natural to define an entity whose task will be to serve as a warehouse for sample points, together with efficient methods or reading them, and in the end -- presenting the results to the user. These things, to some extent, can be done for any probability measure defined by the user. 

The Object Oriented paradigm gives the programmer the tool of inheritance. Its role is to assure no code copying when several programmes share the same structure and differ only at some minor implementation details. In this implementation we have noticed that the \PT, being an extension to the \MH, differs only in the appearance of the swap stage and its methods, the Random Walk stage being almost the same\footnote{The difference being that it is called for several chains instead of one.}.    

All the entities must be linked, so that different parts of programme could call methods of other entities. Because of certain Reference Classes limititions\footnote{As pointed out before, Reference Classes are relatively new, and, as such, poorly documented. With trial and error it has been checked, that this particular choice of entity-nesting simply works.}, the Algrorithm has a pointer on the State Space, which in its turn has a pointer on the Target Measure. These relationships are visualised in Figure \ref{objectStructure} under the form of golden arrows. Under different circumstances, different realisations of objects will appear as the Algorithm, the State Space, and the Target Measure. For instantance, if the user wanted to carry out standard Metropolis-Hastings calculations on the three-dimensional euclidean space and check how it copes with the density function he provided, then the programme would have to initialise first the Unnormalised Density as the realisation of the Target Measure entity. Then, initialise the Real space as an instatiation of the State Space and set the pointer for the previously initialised. Finally, it would initialise the Metropolis-Hastings as the operational Algorithm and set the pointer on the previously initialised State Space, being the Real space. To automate this chain of initialisations, a controller entity was established under the name of Simulation ( see Figure \ref{objectStructure} ). Two additional functions were written, \textsc{Metro} and \textsc{PT}, serving as wrappers to the more general Reference Class constructor of the Simulation object. 

Continuing on the example, the user would simply had to call

\begin{lstlisting}
	Example <- Metro(
		n = 1000,
		space = 'real',
		spaceDim = 2,
		targetDensity = userDefinedDensity
	)
\end{lstlisting}  
where \textsc{userDefinedDensity} is an R-implemented unnormalised density function\footnote{In future versions \Cpp\, calls will be usable.}.  

The presented object structure is far from final. Hopefully it will evolve in time, trying to match the needs of various users. We already plan the separation of the swap distributions from the Parallel Tempering entity, giving the user the possibility to check his own swapping strategies, possibly better suited for their needs.


To guarantee user-friendliness, the most common \sspace --- the multidimensional Euclidean space --- has been provided, so that the user can carry out computations specifying only the required minimum - the density function of the measure of interest. With future releases of the software, more standard State Spaces are scheduled for implemention as well, giving the practitioners experience the potentials and drawbacks of Metropolis-Hastings-like stochastic simulations.

\RR\, offers several implemented meta-structures that enable basic object oriented programming techniques. Among these there are the \textbf{S3} classes, \textbf{S4} classes, and the most recent Reference Classes. The implementation of \Metro\, was carried out using Reference Classes. This choice was dictated by several reasons. First, only \textbf{S4} classes and Reference classes offer the possibility of basic type verification\footnote{Still far from the \Cpp\, standards though.}. This assured that no serious errors were introduced in the implementation phase and that users cannot provide absurd input for the algorithm. Moreover, the Reference Classes are the only implementation of objects that use passing arguments by reference, that a priori could saved some time in the calculations on unnecessary object copying\footnote{Altough no serious differences in execution time were actually spoted when comparing both the functionally programmed prototype with the object-oriented final version.}. Finally, the Reference Classes are considered to be highly compatible with \Cpp\, precompiled programmes called from \RR. This is a clear advantage, as the future shipments of \Metro\, are planned to be implemented in \Cpp, so that users can simulate faster that the whole programme was more memory efficient.   

	% \bibliographystyle{./bibliography/eccaNoNotes}
	% \bibliography{myBooks}

\end{document}